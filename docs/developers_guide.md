# Developers Guide: Peripheral Models

This guide outlines the process for implementing and testing new peripheral vision models (visual transforms) in Scrutinizer.

## Architecture Overview

Scrutinizer uses a custom WebGL renderer (`webgl-renderer.js`) to apply fragment shaders to captured browser content. The core logic resides in the fragment shader's `main` function, which determines how pixels are processed based on their distance from the fovea (mouse cursor).

### Key Components

1.  **`webgl-renderer.js`**: The main WebGL class. Contains the shader source code (`fsSource`) and handles uniform binding.
2.  **`scrutinizer.js`**: The high-level controller that manages the renderer, mouse tracking, and configuration.
3.  **`menu-template.js`**: Defines the critical application menu, including simulation settings.
4.  **`docs/architecture-module-pattern.md`**: **CRITICAL** - Explains the hybrid CommonJS/Window module pattern used to prevent `ReferenceError`s. Read this before refactoring any class files.

## Adding a New Peripheral Model (WIP API)

Currently, adding a new visual effect involves modifying the core shader code. We are working on a plugin API to allow dynamic loading of effects.

### 1. Define the Mode
Add a new mode ID in `menu-template.js` and `webgl-renderer.js`.
-   **0.0**: High-Key Ghosting (Default)
-   **1.0**: Lab Mode (Scotopic)
-   **2.0**: Frosted Glass
-   **3.0**: Blueprint
-   **4.0**: Cyberpunk
-   **5.0**: [Your New Model]

### 2. Implement Shader Logic
In `webgl-renderer.js`, locate the `applyAestheticEffect` function in the fragment shader. Add a new branch for your mode:

```glsl
} else if (u_aesthetic_mode < 5.5) {
    // === 5: YOUR NEW MODEL ===
    // Implement your visual transform here
    
    // Example: Simple Red Tint
    vec3 redTint = vec3(1.0, 0.0, 0.0);
    vec3 final = mix(col, redTint, effectFactor);
    
    return mix(col, final, effectFactor);
}
```

**Best Practices:**
-   **Visual Scent**: The goal is to provide a "scent" of the content without full detail.
-   **Performance**: Avoid loops. Use `texture2D` lookups efficiently.
-   **Explicit Sequencing**: If using distortion, calculate the offset *once* and reuse it for all samples to save performance.

### 3. Expose in UI
Update `menu-template.js` to add a radio button for your new mode in the "Aesthetic Mode" submenu.

```javascript
{
    label: 'My New Model',
    type: 'radio',
    click: () => sendToOverlays('menu:set-aesthetic-mode', 5)
}
```

## Future Roadmap: Abstraction

We plan to abstract the "Peripheral Model" into a pluggable system where shaders can be loaded dynamically or defined in separate files, making it easier to experiment with deep-learning-based texture synthesis models.

---

## Working with Texture-Based Pipelines

Scrutinizer provides auxiliary texture maps that encode semantic and perceptual information about the content. These textures can be sampled in your shader to create content-aware effects.

### Available Texture Uniforms

#### 1. Structure Map (`u_structureMap`)

**Purpose**: Encodes layout semantics (rhythm, mass, element type) for content-aware distortion.

**RGBA Channels:**
- **Red**: `lineHeight / 100.0` - Vertical rhythm of text
- **Green**: `density (0.0-1.0)` - Visual weight (font weight, image brightness)
- **Blue**: `semantics` - Element type: Text (1.0), Image (0.5), UI (0.0)
- **Alpha**: `1.0` for content, `0.0` for whitespace

**Usage Example:**
```glsl
uniform sampler2D u_structureMap;

vec4 structure = texture2D(u_structureMap, uv);
float rhythm = structure.r * 100.0; // lineHeight in pixels
float mass = structure.g;           // 0.0 = light, 1.0 = heavy
float isText = structure.b;         // 1.0 = text, 0.0 = UI

// Example: Only blur images, not text
float blurAmount = mix(0.0, 10.0, 1.0 - isText);

// Example: Distort based on visual mass
float warpStrength = mass * 5.0;
```

**Source**: Generated by `DomAdapter` (web) or `FigmaAdapter` (Figma plugin) via structure map pipeline.

#### 2. Saliency Map (`u_saliencyMap`) - *Coming Soon*

**Purpose**: Bottom-up attention map for clutter-driven distortion and creative effects.

**Channel:**
- **Red**: `saliency (0.0-1.0)` - High = distinctive features, Low = visual clutter

**Usage Example:**
```glsl
uniform sampler2D u_saliencyMap;

float saliency = texture2D(u_saliencyMap, uv).r;
float clutterStrength = 1.0 - saliency; // Inverse saliency

// Example: Crowding model - high distortion in clutter
float crowdingFactor = mix(1.0, clutterStrength, peripheralMask);
warpOffset *= crowdingFactor;

// Example: VFX spotlight - glow on high-saliency regions
vec3 glowColor = vec3(1.0, 0.8, 0.2);
vec3 spotlight = col + glowColor * saliency * 0.3;
```

**Dual Purpose:**
1. **VFX Tool**: Creative layer for visual artists
2. **Core Simulation**: Biophysical accuracy (attention-driven distortion)

### Best Practices for Texture Sampling

**Performance:**
- Sample textures once per fragment, store in variables
- Avoid multiple `texture2D` calls with same UV

**Coordinate Spaces:**
- Structure map is in viewport space (same as `uv`)
- Distorted lookups: Use original `uv` for structure map, distorted `uv` for source image

**Combining Maps:**
```glsl
// Sample both maps
vec4 structure = texture2D(u_structureMap, uv);
float saliency = texture2D(u_saliencyMap, uv).r;

// Combine for hybrid effect
float combinedMask = structure.g * (1.0 - saliency); // Heavy, low-attention areas
float distortionStrength = combinedMask * peripheralMask;
```

### Debugging Texture Maps

Add debug visualization modes to inspect map contents:

```glsl
// Toggle via u_debug_mode uniform
if (u_debug_mode == 1.0) {
    // Visualize structure map channels
    vec4 structure = texture2D(u_structureMap, uv);
    gl_FragColor = vec4(structure.rgb, 1.0);
    return;
} else if (u_debug_mode == 2.0) {
    // Visualize saliency heatmap
    float saliency = texture2D(u_saliencyMap, uv).r;
    vec3 heatmap = vec3(saliency, 0.0, 1.0 - saliency); // Red-to-blue
    gl_FragColor = vec4(heatmap, 1.0);
    return;
}
```

---

## Contributing New Effects

When developing new models that use these textures:

1. **Document channel usage** in code comments
2. **Add debug modes** to visualize intermediate maps
3. **Test both web and Figma** to ensure unified pipeline works
4. **Consider performance** - texture lookups are fast, but avoid redundancy

See `ROADMAP.md` for upcoming saliency map integration details.
